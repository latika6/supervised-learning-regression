{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning : signs to identify hdden pattern in the dataset\n",
    "# it is the process to enable computer based system that define on statistical and mathematical methods\n",
    "# model generated reprsents behavior of the process\n",
    "# larger data, more representative data to be - more accurate model to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning algorothim \n",
    "# look for pattern\n",
    "# trends, cycles, associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning use-cases\n",
    "#1. character recognition\n",
    "#2. spam mail detection\n",
    "#3. weather forecasting\n",
    "#4. genetic code mapping\n",
    "#5. mars rover\n",
    "#6. recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature of Mathematical Space\n",
    "#Feature Space\n",
    "#the data represent in the mathematical space\n",
    "#each attribute become a dimension\n",
    "#each record become a point in the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test-fit model\n",
    "# ax + by + cz = d\n",
    "# x, y, z are three dimensions\n",
    "# modelling can be done in 2 dimesnions as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUPERVISED MACHINE LEARNING \n",
    "# 1 stage - training set (70:30)\n",
    "# 2 stage - test set\n",
    "# Idenepndent variables\n",
    "# Target Variables\n",
    "# model represent on hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRISP-DM, or Cross-Industry Standard Process for Data Mining, is a structured methodology that provides a way to plan, organize, and implement data mining projects. \n",
    "# The process includes six major phases:\n",
    "# Business understanding: Identify the project's objectives and strategy\n",
    "# Data understanding: Describe the data\n",
    "# Data preparation: Prepare the data\n",
    "# Modeling: Build and assess models using different techniques\n",
    "# Evaluation: Determine which model best meets the business objectives\n",
    "# Deployment: Plan for deploying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR REGRESSION\n",
    "# response = intercept + constant * explanatory\n",
    "# Pearson correlation range (-1 and +1)\n",
    "# 0 represents no relation\n",
    "# when r value is small, need to test again r has some correlation\n",
    "# if r near 0, model will not be reliable\n",
    "# Non linear model are better in such cases\n",
    "# if the Pearson coefficient value is exactly 0 then it means that both variables have no linear relation \n",
    "# but it does not mean that they do not have a relation they might have other relations such as nonlinear relation.\n",
    "# Regression word in the linear regression algorithm refers to predicting the real number. reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y axis = target variable\n",
    "# x-axis = independent variable\n",
    "# sum of sqrd errors\n",
    "# Error = T - (mx + C) ~ 0\n",
    "# y = mx + b\n",
    "# r**2 \n",
    "# adjustant r**2 = r**2 - fluke\n",
    "# The error that is captured by the model is also known as the sum of squared error. Hence it's also called regression error.\n",
    "# The SSE is the error that is not explained by the model. Hence it is called residual error.\n",
    "# The Linear Regression algorithm tries to fit the line where the error is less that the final line we call as best fit line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adv vs Dis\n",
    "# implement easier\n",
    "# disadv - 1. expect to be linear\n",
    "# 2. outlier may impact linear regression\n",
    "# 3. LR look for relationships\n",
    "# 4. LR assume independence between attributes\n",
    "# 5. LR is not complete description of relationship between varibales\n",
    "# 6. boundaries are linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 dependent & 1 independent - Univariant \n",
    "# y = f(X) where f = model\n",
    "# marks = f(hrs)\n",
    "# residual errors\n",
    "# The best-fit line is the line where the sum of squares is minimum across all the data points. so the difference of y - y_hat will be very close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Analysis\n",
    "# SSE = (y - yhat)**2/ n\n",
    "# Residual = Actual - Predicted\n",
    "# total error (TE) = y - y(bar)\n",
    "# TE = Regression Error + Residual Error\n",
    "# r**2 = coeff of determinant (coeff of correlation)\n",
    "# r** 2 = ration of regression error to total errors\n",
    "# if r**2 close to 1 then the data points are close to line\n",
    "# if r**2 close to 0 then the data points are far away from the line\n",
    "# R**2 is nothing but the coefficient of determination, which simply tells the percentage of variation that is captured by the model out of overall variation.\n",
    "# note: r**2 is not consider in multivariant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLUKE CORRELATION\n",
    "# R > 0 \n",
    "# Not symmetrically distributed\n",
    "# Adjusted R square\n",
    "# R2 does not eliminate statistical fluke whereas Adjusted R2 eliminates the statistical fluke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR REGRESSION THEORY\n",
    "# assumption relate characteristics of function/ model in the population\n",
    "# applicable to population \n",
    "# assumption may not hold - we should not build linear models\n",
    "# 1st assumption - y and x relation is linear in terms of coeff\n",
    "# Ui = impact on y on other variable which is not part of the model\n",
    "# assumption 2 = x value independent of error terms\n",
    "# assumption 3 = the mean value of disturbance of ui is zero\n",
    "# Homoscedasticity || hetero\n",
    "# assumption 4 = \n",
    "# assumption 5 = no autocorrelation\n",
    "# assumption 6 = no. of observation greater than no. of parameters\n",
    "# assumption 7 = x should have variance, the values should not be constant\n",
    "# assumption 8 = no perfect collinearity\n",
    "# assumption 9 = model is correctly specified\n",
    "# assumption 10 = stochastic ui is normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y= mx+c\n",
    "# What does the m mean from the above formula?\n",
    "# M refers to beta 1(slope)\n",
    "\n",
    "# The multicollinearity is the correlation between the independent variables, resulting in the coefficient being unreliable.\n",
    "\n",
    "# The difference between the model-predicted values and the actual y values should not have a relationship with themself(should not follow a certain pattern).\n",
    "# No presence of autocorrection tells us that errors have no correlation among themself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stichastic term (Ui)\n",
    "# Occam's razor\n",
    "# assumption 3 = mean value of disturbance is 0\n",
    "# The UI is an error, which is a collective impact of the variables which have not been considered to predict the desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heteroscedasicity - The unequal variance of residuals over the range of measured values is known as heteroscedasticity.\n",
    "# non - linear\n",
    "# Collecting insufficient data\n",
    "# outliers\n",
    "# skewness\n",
    "# models specified is not correct\n",
    "# more heteroscedasciity , lesser weightage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
